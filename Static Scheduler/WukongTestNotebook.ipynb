{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8f94f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically starting the KV Store Proxy locally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:10:59,422] DEBUG: To start diagnostics web server please install Bokeh\n",
      "[2023-04-03 19:10:59,460] DEBUG: aws_region: us-east-1\n",
      "[2023-04-03 19:10:59,495] DEBUG: Redis proxy listening on port 8989\n",
      "[2023-04-03 19:10:59,495] DEBUG: [ 2023-04-03 19:10:59.495573 ] Connecting to Redis server...\n",
      "[2023-04-03 19:10:59,496] DEBUG: [ 2023-04-03 19:10:59.496318 ] Connected to Redis successfully!\n",
      "[2023-04-03 19:10:59,521] INFO:   Scheduler at:    tcp://10.0.88.131:8786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Lambda function names specified directly in configuration file.\n",
      "Executor Function Name: \"WukongExecutor\"\n",
      "Invoker Function Name: \"WukongInvoker\"\n",
      "Starting BatchedLambdaInvoker with interval 0.002...\n",
      "[ 2023-04-03 19:10:59.522505 ] BatchedLambdaInvoker - INFO: Launching 4 ''Lambda Invoker'' processes.\n",
      "BatchedLambdaInvoker - Executor function name: \"WukongExecutor\"\n",
      "BatchedLambdaInvoker - Invoker function name: \"WukongInvoker\"\n",
      "[ 2023-04-03 19:10:59.530891 ] - Lambda Invoker Process 0 - INFO: Lambda Invoker Process began executing...\n",
      "[ 2023-04-03 19:10:59.535011 ] - Lambda Invoker Process 1 - INFO: Lambda Invoker Process began executing...[ 2023-04-03 19:10:59.542959 ] - Lambda Invoker Process 2 - INFO: Lambda Invoker Process began executing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:10:59,556] INFO: Creating 1 redis-polling processes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Creating 1 redis-polling processes.\n",
      "[ 2023-04-03 19:10:59.558091 ] - Lambda Invoker Process 3 - INFO: Lambda Invoker Process began executing...Redis Polling Process started. Polling channel \n",
      " dask-workers-1\n",
      "-=-=-=-=-=-=-=- SCHEDULER ID: 7912G -=-=-=-=-=-=-=-\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import dask \n",
    "import time \n",
    "from wukong import Client, LocalCluster, get_task_stream\n",
    "from dask import delayed \n",
    "import logging \n",
    "\n",
    "lc = LocalCluster(\n",
    "  host=\"10.0.88.131:8786\",\n",
    "  proxy_address = \"10.0.88.131\",\n",
    "  proxy_port = 8989,\n",
    "  num_lambda_invokers = 4,\n",
    "  chunk_large_tasks = False,\n",
    "  n_workers = 0,\n",
    "  use_local_proxy = True,\n",
    "  local_proxy_path = \"/home/ec2-user/Wukong/KV Store Proxy/proxy.py\",\n",
    "  redis_endpoints = [(\"127.0.0.1\", 6379)],\n",
    "  use_fargate = False)\n",
    "client = Client(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97af0208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:11:31,914] DEBUG: =-=-=-= [SCHEDULER] update_graph() #1 --- ID: 948CF (Scheduler ID is 7912G) =-=-=-=\n",
      "[2023-04-03 19:11:31,932] DEBUG: Number of Paths created: 1.\n",
      "[2023-04-03 19:11:31,933] DEBUG: Done serializing all 1 payloads. Took 8.225440979003906e-05 seconds. Storing paths in Redis now.\n",
      "[2023-04-03 19:11:31,935] DEBUG: Done storing paths in Redis. Invoking Lambdas now.\n",
      "[2023-04-03 19:11:31,936] DEBUG: [ 2023-04-03 19:11:31.935972 ] - Scheduler: 1 leaf tasks have been submitted for invocation while 0 were already existing (1 total).\n",
      "[2023-04-03 19:11:31,936] DEBUG: [INFO] Largest Fanout: Task  with a fanout factor of 0!\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 1025, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 869, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 608, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib64/python3.7/threading.py\", line 890, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib64/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/utils.py\", line 410, in run_loop\n",
      "    loop.start()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib64/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib64/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib64/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/ioloop.py\", line 687, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/ioloop.py\", line 740, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 821, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 782, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/core.py\", line 478, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/scheduler.py\", line 2895, in update_graph\n",
      "    logger.debug(\"Number of Tasks: \", len(tasks))\n",
      "Message: 'Number of Tasks: '\n",
      "Arguments: (1,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 1025, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 869, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 608, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib64/python3.7/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib64/python3.7/threading.py\", line 890, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib64/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/utils.py\", line 410, in run_loop\n",
      "    loop.start()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib64/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib64/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib64/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/ioloop.py\", line 687, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/ioloop.py\", line 740, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 821, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 782, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/core.py\", line 478, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/scheduler.py\", line 2896, in update_graph\n",
      "    logger.debug(\"Number of Leaf Tasks: \", len(leaf_tasks))\n",
      "Message: 'Number of Leaf Tasks: '\n",
      "Arguments: (1,)\n",
      "[2023-04-03 19:11:31,943] DEBUG: Update graph duration was 0.023482799530029297 seconds.\n",
      "[2023-04-03 19:11:31,943] DEBUG: DFS took 0.0008864402770996094 seconds...\n",
      "[2023-04-03 19:11:31,944] DEBUG: Path-Serialization took 8.225440979003906e-05 seconds...\n",
      "[2023-04-03 19:11:31,945] DEBUG: Store-Paths-Redis took 0.0005121231079101562 seconds...\n",
      "[2023-04-03 19:11:31,946] DEBUG: Enqueue-Leaf-Task-Invocations took 7.390975952148438e-05 seconds...\n",
      "[2023-04-03 19:11:32,176] DEBUG: Stimulus task finished on AWS Lambda incr-687eaf01-b64b-4c5e-8b8c-f94fddf3f646\n",
      "[2023-04-03 19:11:32,181] INFO: Scheduler closing...\n",
      "[2023-04-03 19:11:32,182] INFO: Scheduler closing all comms\n",
      "[2023-04-03 19:11:32,184] DEBUG: Client Client-44bd13da-d253-11ed-bbf3-0a4c26d3002b releases keys: ['incr-687eaf01-b64b-4c5e-8b8c-f94fddf3f646']\n",
      "[2023-04-03 19:11:32,185] DEBUG: Finished handling client Client-44bd13da-d253-11ed-bbf3-0a4c26d3002b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:11:32.179496] -- CLIENT -- Retrieving values for 1 keys.\n",
      "[CLIENT] Obtained value for key incr-687eaf01-b64b-4c5e-8b8c-f94fddf3f646 from Redis.\n",
      "[CLIENT] Returning {'status': 'OK', 'data': {'incr-687eaf01-b64b-4c5e-8b8c-f94fddf3f646': 4}} to the user...\n",
      "Result: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timeout\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1015, in _reconnect\n",
      "    yield self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 776, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1060, in _ensure_connected\n",
      "    msg = yield gen.with_timeout(timedelta(seconds=timeout), comm.read())\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "concurrent.futures._base.TimeoutError: Timeout\n",
      "Timeout\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1164, in _handle_report\n",
      "    yield self._reconnect()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 776, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1015, in _reconnect\n",
      "    yield self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 776, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1060, in _ensure_connected\n",
      "    msg = yield gen.with_timeout(timedelta(seconds=timeout), comm.read())\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "concurrent.futures._base.TimeoutError: Timeout\n"
     ]
    }
   ],
   "source": [
    "def incr(x):\n",
    "  return x + 1\n",
    "\n",
    "inc = dask.delayed(incr)\n",
    "\n",
    "z = inc(3)\n",
    "res = z.compute(scheduler = client.get)\n",
    "print(\"Result:\", res)\n",
    "\n",
    "lc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73673578",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb70367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
