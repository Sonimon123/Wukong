{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0323aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically starting the KV Store Proxy locally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:12:05,210] DEBUG: aws_region: us-east-1\n",
      "[2023-04-03 19:12:05,216] DEBUG: To start diagnostics web server please install Bokeh\n",
      "[2023-04-03 19:12:05,266] DEBUG: Redis proxy listening on port 8989\n",
      "[2023-04-03 19:12:05,266] DEBUG: [ 2023-04-03 19:12:05.266811 ] Connecting to Redis server...\n",
      "[2023-04-03 19:12:05,267] DEBUG: [ 2023-04-03 19:12:05.267682 ] Connected to Redis successfully!\n",
      "[2023-04-03 19:12:05,337] INFO:   Scheduler at:    tcp://10.0.88.131:8786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Lambda function names specified directly in configuration file.\n",
      "Executor Function Name: \"WukongExecutor\"\n",
      "Invoker Function Name: \"WukongInvoker\"\n",
      "Starting BatchedLambdaInvoker with interval 0.002...\n",
      "[ 2023-04-03 19:12:05.338747 ] BatchedLambdaInvoker - INFO: Launching 4 ''Lambda Invoker'' processes.\n",
      "BatchedLambdaInvoker - Executor function name: \"WukongExecutor\"\n",
      "BatchedLambdaInvoker - Invoker function name: \"WukongInvoker\"\n",
      "[ 2023-04-03 19:12:05.346421 ] - Lambda Invoker Process 0 - INFO: Lambda Invoker Process began executing...\n",
      "[ 2023-04-03 19:12:05.351099 ] - Lambda Invoker Process 1 - INFO: Lambda Invoker Process began executing...\n",
      "[ 2023-04-03 19:12:05.364016 ] - Lambda Invoker Process 2 - INFO: Lambda Invoker Process began executing...[ 2023-04-03 19:12:05.370489 ] - Lambda Invoker Process 3 - INFO: Lambda Invoker Process began executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:12:05,374] INFO: Creating 1 redis-polling processes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "Creating 1 redis-polling processes.\n",
      "Redis Polling Process started. Polling channel  dask-workers-1\n",
      "-=-=-=-=-=-=-=- SCHEDULER ID: 2606R -=-=-=-=-=-=-=-\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import dask \n",
    "import time \n",
    "from wukong import Client, LocalCluster, get_task_stream\n",
    "from dask import delayed \n",
    "import logging \n",
    "\n",
    "lc = LocalCluster(\n",
    "  host=\"10.0.88.131:8786\",\n",
    "  proxy_address = \"10.0.88.131\",\n",
    "  proxy_port = 8989,\n",
    "  num_lambda_invokers = 4,\n",
    "  chunk_large_tasks = False,\n",
    "  n_workers = 0,\n",
    "  use_local_proxy = True,\n",
    "  local_proxy_path = \"/home/ec2-user/Wukong/KV Store Proxy/proxy.py\",\n",
    "  redis_endpoints = [(\"127.0.0.1\", 6379)],\n",
    "  use_fargate = False)\n",
    "client = Client(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66d14e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:12:05,424] DEBUG: =-=-=-= [SCHEDULER] update_graph() #1 --- ID: 7504KL (Scheduler ID is 2606R) =-=-=-=\n",
      "[2023-04-03 19:12:05,439] DEBUG: Number of Paths created: 1.\n",
      "[2023-04-03 19:12:05,441] DEBUG: Done serializing all 1 payloads. Took 8.630752563476562e-05 seconds. Storing paths in Redis now.\n",
      "[2023-04-03 19:12:05,443] DEBUG: Done storing paths in Redis. Invoking Lambdas now.\n",
      "[2023-04-03 19:12:05,445] DEBUG: [ 2023-04-03 19:12:05.445032 ] - Scheduler: 1 leaf tasks have been submitted for invocation while 0 were already existing (1 total).\n",
      "[2023-04-03 19:12:05,445] DEBUG: [INFO] Largest Fanout: Task  with a fanout factor of 0!\n",
      "[2023-04-03 19:12:05,446] DEBUG: Number of Tasks: 1\n",
      "[2023-04-03 19:12:05,447] DEBUG: Number of Leaf Tasks: 1\n",
      "[2023-04-03 19:12:05,448] DEBUG: Update graph duration was 0.022418498992919922 seconds.\n",
      "[2023-04-03 19:12:05,449] DEBUG: DFS took 0.0009169578552246094 seconds...\n",
      "[2023-04-03 19:12:05,450] DEBUG: Path-Serialization took 8.630752563476562e-05 seconds...\n",
      "[2023-04-03 19:12:05,451] DEBUG: Store-Paths-Redis took 0.0009567737579345703 seconds...\n",
      "[2023-04-03 19:12:05,452] DEBUG: Enqueue-Leaf-Task-Invocations took 7.891654968261719e-05 seconds...\n",
      "[2023-04-03 19:12:05,648] DEBUG: Stimulus task finished on AWS Lambda incr-63b1a93e-beb0-4c38-a2d7-722c68cad89f\n",
      "[2023-04-03 19:12:05,653] INFO: Scheduler closing...\n",
      "[2023-04-03 19:12:05,654] INFO: Scheduler closing all comms\n",
      "[2023-04-03 19:12:05,656] DEBUG: Client Client-6bf82194-d253-11ed-bcbb-0a4c26d3002b releases keys: ['incr-63b1a93e-beb0-4c38-a2d7-722c68cad89f']\n",
      "[2023-04-03 19:12:05,657] DEBUG: Finished handling client Client-6bf82194-d253-11ed-bcbb-0a4c26d3002b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-03 19:12:05.651748] -- CLIENT -- Retrieving values for 1 keys.\n",
      "[CLIENT] Obtained value for key incr-63b1a93e-beb0-4c38-a2d7-722c68cad89f from Redis.\n",
      "[CLIENT] Returning {'status': 'OK', 'data': {'incr-63b1a93e-beb0-4c38-a2d7-722c68cad89f': 4}} to the user...\n",
      "Result: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timeout\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1015, in _reconnect\n",
      "    yield self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 776, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1060, in _ensure_connected\n",
      "    msg = yield gen.with_timeout(timedelta(seconds=timeout), comm.read())\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "concurrent.futures._base.TimeoutError: Timeout\n",
      "Timeout\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/utils.py\", line 713, in log_errors\n",
      "    yield\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1164, in _handle_report\n",
      "    yield self._reconnect()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 776, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1015, in _reconnect\n",
      "    yield self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 776, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home/ec2-user/Wukong/Static Scheduler/wukong/client.py\", line 1060, in _ensure_connected\n",
      "    msg = yield gen.with_timeout(timedelta(seconds=timeout), comm.read())\n",
      "  File \"/home/ec2-user/.local/lib/python3.7/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "concurrent.futures._base.TimeoutError: Timeout\n"
     ]
    }
   ],
   "source": [
    "def incr(x):\n",
    "  return x + 1\n",
    "\n",
    "inc = dask.delayed(incr)\n",
    "\n",
    "z = inc(3)\n",
    "res = z.compute(scheduler = client.get)\n",
    "print(\"Result:\", res)\n",
    "\n",
    "lc.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
